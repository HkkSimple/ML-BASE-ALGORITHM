{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class information:\n",
    "    #每一类样本数、总样本数、类别数、先验概率、特征统计信息\n",
    "    def __init__(self,class_sample_num, sample_num, class_num, prior_probability, feature_probability):\n",
    "        self.class_sample_num = class_sample_num\n",
    "        self.sample_num = sample_num\n",
    "        self.class_num = class_num\n",
    "        self.prior_probability = prior_probability\n",
    "        self.feature_probability = feature_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n",
    "    return postingList,classVec\n",
    "#postingList = loadDataSet()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#去除所有重复词，并且组成一个向量\n",
    "def createFeature(dataset):\n",
    "    temp = set()\n",
    "    map(lambda s: temp.update(s), dataset)\n",
    "    return list(temp)\n",
    "#list_feature = createFeature(postingList)\n",
    "\n",
    "#将数据集中的每个sample都表示成特征向量的形式，sample中的词对应特征向量的中为1的位置\n",
    "def wordVector(dataset,list_feature): \n",
    "    len_dataset = len(dataset)\n",
    "    len_features = len(list_feature)\n",
    "    #初始化sample的特征向量\n",
    "    vector_sample = np.zeros((len_dataset, len_features))                \n",
    "    for i, sample in enumerate(dataset):\n",
    "        for word in sample:\n",
    "            index = list_feature.index(word)\n",
    "            vector_sample[i][index] += 1\n",
    "    return vector_sample        \n",
    "\n",
    "#wordVector(postingList, list_feature)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#统计每个类，每一个特征中，所有可能取值的个数返回{类别：{特征{取值:}}}\n",
    "def statistics(X_data, y_data):\n",
    "    y_data = y_data.iloc[:,0]\n",
    "    info = information(dict, 0, 0, 0, dict())\n",
    "     \n",
    "    #存储每个特征不同取值的条件概率\n",
    "    feature_probability = dict()\n",
    "    #样本总数\n",
    "    total_sample = y_data.shape[0]\n",
    "    \n",
    "    #一个Series，index是类别名，value是该类的样本数目\n",
    "    class_info = y_data.value_counts()    \n",
    "    #label的名字，也就是index\n",
    "    labels = list(class_info.index)\n",
    "    #数据集中出现的类别数\n",
    "    labels_counts = class_info.shape[0]\n",
    "    #计算先验概率,用拉普拉斯平滑一下,Series的数据格式\n",
    "    prior_probability = 1.0 * (class_info + 1) / (total_sample + labels_counts)\n",
    "    #存储每类样本数\n",
    "    class_sample_num = dict()\n",
    "    for label in labels:\n",
    "        label_x_data = X_data[y_data == label]         \n",
    "        class_sample_num[label] = label_x_data.shape[0]                \n",
    "        feature_probability[label] = dict()\n",
    "        for col in label_x_data:\n",
    "            feature_probability[label][col] = {}\n",
    "            #每个特征的可能取值\n",
    "            feature_probability[label][col].update(dict(label_x_data[col].value_counts()))\n",
    "    #存储每类样本数\n",
    "    info.class_sample_num = class_sample_num\n",
    "    #存储样本总数\n",
    "    info.sample_num = total_sample\n",
    "    #存储类别数\n",
    "    info.class_num = labels_counts\n",
    "    #存数先验概率\n",
    "    info.prior_probability = prior_probability\n",
    "    #存储特征的统计学习\n",
    "    info.feature_probability = feature_probability\n",
    "    \n",
    "    return info\n",
    "#statistics(X_data, y_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:       0    1    2     3     4    5    6    7     8     9   ...    22    23  \\\n",
       " 0.0  0.6  0.6  0.6  1.00  1.00  0.6  0.6  0.6  1.00  1.00  ...   0.4  1.00   \n",
       " 1.0  0.4  0.4  0.4  0.25  0.25  0.4  0.4  0.4  0.25  0.25  ...   0.6  0.25   \n",
       " \n",
       "       24    25   26    27   28   29   30    31  \n",
       " 0.0  0.6  1.00  0.6  1.00  0.6  0.6  0.6  0.25  \n",
       " 1.0  0.4  0.25  0.4  0.25  0.4  0.4  0.4  1.00  \n",
       " \n",
       " [2 rows x 32 columns],\n",
       " 1:        0     1     2    3    4     5    6     7    8    9   ...    22   23  \\\n",
       " 0.0  1.00  1.00  1.00  0.6  0.6  1.00  0.6  1.00  0.6  0.4  ...   0.6  0.6   \n",
       " 1.0  0.25  0.25  0.25  0.4  0.4  0.25  0.4  0.25  0.4  0.6  ...   0.4  0.4   \n",
       " \n",
       "        24   25   26    27    28    29    30    31  \n",
       " 0.0  1.00  0.6  0.4  0.25  1.00  1.00  1.00  1.00  \n",
       " 1.0  0.25  0.4  0.6  1.00  0.25  0.25  0.25  0.25  \n",
       " \n",
       " [2 rows x 32 columns]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''计算给定样本的朴素贝叶斯分类器的值，\n",
    "之后只要通过查表（probability）就能立马得出每一类的概率，\n",
    "取最大概率的类标签为要预测或分类sample的类'''\n",
    "def calcProbability(X_data, y_data):    \n",
    "    info = statistics(X_data, y_data)\n",
    "    feature_info = info.feature_probability\n",
    "    probability = {}\n",
    "    for label, value in feature_info.items():\n",
    "        df = DataFrame(value)        \n",
    "        temp_df = df.copy()\n",
    "        df.fillna(0,inplace =True)\n",
    "        #每类样本数\n",
    "        class_sample_num = info.class_sample_num[label]  \n",
    "        for col in df:\n",
    "            #每个特征的可能取值数\n",
    "            feature_value_unique_num = len(temp_df[col].dropna())\n",
    "            df[col] = (df[col] + 1) / (class_sample_num + feature_value_unique_num)\n",
    "            probability[label] = df  \n",
    "        \n",
    "    return probability                 \n",
    "calcProbability(X_data.iloc[0], X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...    22   23   24   25  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  1.0   \n",
       "2  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0 ...   1.0  0.0  1.0  0.0   \n",
       "5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0 ...   0.0  1.0  0.0  0.0   \n",
       "\n",
       "    26   27   28   29   30   31  \n",
       "0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1  1.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.0  1.0  1.0  \n",
       "5  1.0  1.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[6 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = loadDataSet()\n",
    "postingList = dataset[0]\n",
    "class_vector = dataset[1]\n",
    "list_feature = createFeature(postingList)\n",
    "arr_data = wordVector(postingList, list_feature)  \n",
    "#整理好的数据集和标签\n",
    "X_data = DataFrame(arr_data)\n",
    "y_data = DataFrame(class_vector)\n",
    "#包含X_data,y_data的合并\n",
    "data = pd.merge(X_data,y_data,left_index=True,right_index=True,how='outer')\n",
    "display(X_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
