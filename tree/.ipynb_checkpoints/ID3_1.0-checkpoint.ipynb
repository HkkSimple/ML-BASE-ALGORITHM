{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from IPython.display import display\n",
    "\n",
    "from math import log\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b label\n",
       "0  1  1   yes\n",
       "1  1  1   yes\n",
       "2  1  0    no\n",
       "3  0  1    no\n",
       "4  0  1    no"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/test_ID3_1.0')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970950594455\n"
     ]
    }
   ],
   "source": [
    "'''1、信息熵的计算\n",
    "   2、默认用DataFrame去处理\n",
    "   3、给定数据集、标签columns名称'''\n",
    "def calcShannonEnt(dataSet, label_col_name):\n",
    "    num_data = dataSet.shape[0]\n",
    "    labels = dataSet[label_col_name]\n",
    "    labels_counter = Counter(labels)\n",
    "    labels_keys = labels_counter.keys()\n",
    "    shannonEnt = 0\n",
    "    for k,v in labels_counter.items():\n",
    "        p = 1.0*v/num_data\n",
    "        shannonEnt -= p*log(p,2)\n",
    "    return shannonEnt\n",
    "print calcShannonEnt(data,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b label\n",
       "0  1   yes\n",
       "1  1   yes\n",
       "2  0    no"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''1、划分数据集\n",
    "   2、给定数据集、划分feature、feature值\n",
    "   3、dataSet默认类型为DataFrame'''\n",
    "def splitDateSet(dataSet,feature_name,feature_value):\n",
    "    filter_bool = (dataSet[feature_name] == feature_value)\n",
    "    splited_data_set = dataSet[filter_bool].drop([feature_name],axis=1,inplace=False)\n",
    "    return splited_data_set\n",
    "display(splitDateSet(data,'a',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best feature to split is --> a\n"
     ]
    }
   ],
   "source": [
    "'''1、选择最好的划分feature\n",
    "   2、通过信息增益标准来划分'''\n",
    "def chooseBestFeatureToSplit(dataSet,label_col_name):\n",
    "    #整个数据集的信息熵\n",
    "    base_entropy = calcShannonEnt(dataSet,label_col_name)    \n",
    "    #选取所有要参加选择的feature，label不参与选择\n",
    "    choose_features = list(dataSet.columns)\n",
    "    choose_features.remove(label_col_name)\n",
    "    #定义一个信息增益的字典用来存储\n",
    "    feature_entropy_change = dict.fromkeys(choose_features)\n",
    "    for feature in choose_features:\n",
    "        feature_values = np.unique(dataSet[feature])\n",
    "        new_entropy = 0\n",
    "        #逐个算当前feature不同取值下的信息熵，最后算出当前feature的信息熵\n",
    "        for feature_value in feature_values:\n",
    "            split_data = splitDateSet(dataSet, feature, feature_value)\n",
    "            p =1.0*split_data.shape[0] / dataSet.shape[0]\n",
    "            new_entropy += p * calcShannonEnt(split_data, label_col_name)\n",
    "        #feature的信息增益字典\n",
    "        feature_entropy_change[feature] = base_entropy - new_entropy\n",
    "    s = Series(feature_entropy_change)\n",
    "    #获取信息增益最大的feature，如果最大信息增益最大的feature有多个，则选择第一个    \n",
    "    return list(s[s==s.max()].index)[0]\n",
    "    #return sorted(feature_entropy_change.items(), key=lambda item:item[1] )[0][0]        \n",
    "print 'best feature to split is --> {}'.format(chooseBestFeatureToSplit(data,'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1、如果所有的属性都被划分完，但还是没有能够将数据完全划分开，这时候利用投票来决定该数据集属于哪一类'''\n",
    "def majority(labels_list):\n",
    "    #这里的labels_list为Series结构    \n",
    "    diff_label = labels_list.value_counts()\n",
    "    max_label = list(diff_label[diff_label==diff_label.max()].index)[0]\n",
    "    return max_label\n",
    "majority(data['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {0: 'no', 1: {'b': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1、用递归来创建树\n",
    "   2、递归的停止条件有2个：\n",
    "       1)、程序遍历完所有划分数据集的属性\n",
    "           如果所有属性都遍历完之后，某一分支上的数据依然不属于同一类，则通过投票决定该数据属于那一类\n",
    "       2）、每个分支下的所有数据都属于同一类\n",
    "   3、这里的dataSet是带有label（标签）栏的\n",
    "'''\n",
    "def createTree(dataSet,labels_name):\n",
    "    feature_num = dataSet.shape[1] - 1\n",
    "    series_labels = dataSet[labels_name]\n",
    "    \n",
    "    #当前数据集label不相等的类别的个数\n",
    "    diff_label = series_labels.unique()\n",
    "    diff_label_num = len(diff_label)\n",
    "    \n",
    "    #类别（label）完全相同则停止继续划分\n",
    "    if diff_label_num == 1:\n",
    "        return diff_label[0]\n",
    "    #遍历完所有特征时，数据集中的类别依然不是完全相同的，则返回出现次数最多的类别\n",
    "    if (diff_label_num >1 and feature_num ==0):\n",
    "        return majority(series_labels)\n",
    "    \n",
    "    best_feature = chooseBestFeatureToSplit(dataSet,labels_name)\n",
    "    myTree = {best_feature:{}}\n",
    "    best_feature_values = dataSet[best_feature].unique()\n",
    "    for value in best_feature_values:\n",
    "        myTree[best_feature][value] = createTree(\n",
    "            splitDateSet(dataSet, best_feature, value),labels_name)\n",
    "    return myTree\n",
    "createTree(data,'label')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''根据决策树，对没有标签的数据进行预测'''\n",
    "def classify(myTree,features,test_data):\n",
    "    #以根节点和其子节点为例，进行简单分析\n",
    "    parent = myTree.keys()[0]\n",
    "    childs = myTree[parent]\n",
    "    #获取根节点的feature在数据上的索引位置\n",
    "    parent_index = features.index(parent)\n",
    "    for k in childs.keys():\n",
    "        #找到test_data数据在根节点属性上的取值，从而进入其子节点的相应分支\n",
    "        if test_data[parent_index] == k:\n",
    "            if type(childs[k]) == dict:\n",
    "                #进入子节点之后，判断子节点是否还是字典，如果不是，那就是叶子节点了\n",
    "                class_label = classify(childs[k], features,test_data)\n",
    "            else:\n",
    "                class_label = childs[k]\n",
    "    return class_label\n",
    "classify(createTree(data,'label'), list(data.columns), [1,0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
